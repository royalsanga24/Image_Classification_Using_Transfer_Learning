{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c6efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd1ceb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:From D:\\Pandas Tut\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pandas Tut\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebd6dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background', 'tench', 'goldfish', 'great white shark', 'tiger shark']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels = []\n",
    "with open(\"ImageNetLabels.txt\", \"r\") as f:\n",
    "    image_labels = f.read().splitlines()\n",
    "image_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0274e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d89f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('datasets/flower_photos')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e12313b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_images_dict = {\n",
    "    'roses': list(data_dir.glob('roses/*')),\n",
    "    'daisy': list(data_dir.glob('daisy/*')),\n",
    "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
    "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
    "    'tulips': list(data_dir.glob('tulips/*')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720a5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_labels_dict = {\n",
    "    'roses': 0,\n",
    "    'daisy': 1,\n",
    "    'dandelion': 2,\n",
    "    'sunflowers': 3,\n",
    "    'tulips': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c642e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "for flower_name, images in flowers_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img,(224,224))\n",
    "        X.append(resized_img)\n",
    "        y.append(flowers_labels_dict[flower_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bbf64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9781bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3448b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd04711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_SHAPE+(3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16a9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0723f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 6405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 6,405\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_of_flowers = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  pretrained_model_without_top_layer,\n",
    "  tf.keras.layers.Dense(num_of_flowers)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "610e0581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "86/86 [==============================] - 63s 661ms/step - loss: 0.8499 - acc: 0.6813\n",
      "Epoch 2/5\n",
      "86/86 [==============================] - 55s 634ms/step - loss: 0.4192 - acc: 0.8561\n",
      "Epoch 3/5\n",
      "86/86 [==============================] - 55s 636ms/step - loss: 0.3334 - acc: 0.8932\n",
      "Epoch 4/5\n",
      "86/86 [==============================] - 55s 639ms/step - loss: 0.2788 - acc: 0.9124\n",
      "Epoch 5/5\n",
      "86/86 [==============================] - 55s 645ms/step - loss: 0.2385 - acc: 0.9291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x141b5f7add0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa1f4558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 20s 657ms/step - loss: 0.3732 - acc: 0.8747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37315401434898376, 0.8747276663780212]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71ed875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 23s 713ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f94e640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['roses', 'daisy', 'dandelion', 'sunflower', 'tulip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8f01155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dandelion'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[np.argmax(predictions[222])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3fb1a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dandelion'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[y_test[222]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15752a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db7f7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "tulip = Image.open(\"tulip1.jfif\").resize(IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b73521f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tulip = np.array(tulip)/255\n",
    "tulip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28d56379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 201ms/step\n"
     ]
    }
   ],
   "source": [
    "result_tulip = model.predict(tulip[np.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcc49352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tulip'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[np.argmax(result_tulip)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74394d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image():\n",
    "    img_name = str(input(\"Enter name of image: \"))\n",
    "    img_open = tulip = Image.open(img_name).resize(IMAGE_SHAPE)\n",
    "    img_resized = np.array(img_open)/255\n",
    "    predicted_result = model.predict(img_resized[np.newaxis, ...])\n",
    "    print(\"The predicted result is: \", classes[np.argmax(predicted_result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "225baad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of image: green_snake.jpg\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "The predicted result is:  roses\n"
     ]
    }
   ],
   "source": [
    "test_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0016267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image1():\n",
    "    img_name = str(input(\"Enter name of image: \"))\n",
    "    img_open = tulip = Image.open(img_name).resize(IMAGE_SHAPE)\n",
    "    img_resized = np.array(img_open)/255\n",
    "    predicted_result = classifier.predict(img_resized[np.newaxis, ...])\n",
    "    print(\"The predicted result is: \", image_labels[np.argmax(predicted_result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f44439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of image: poopi.jpg\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "The predicted result is:  kelpie\n"
     ]
    }
   ],
   "source": [
    "test_image1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770f668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
